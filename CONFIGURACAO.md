# Configura√ß√£o da Conex√£o Frontend-Backend

## Vis√£o Geral

Este projeto consiste em um frontend Next.js que se comunica com um backend Python FastAPI para gerar relat√≥rios m√©dicos usando IA.

## Estrutura do Projeto

```
medical-ai-report/
‚îú‚îÄ‚îÄ app/                    # Frontend Next.js
‚îú‚îÄ‚îÄ backend/               # Backend Python FastAPI
‚îú‚îÄ‚îÄ components/            # Componentes React
‚îú‚îÄ‚îÄ lib/                   # Utilit√°rios e configura√ß√µes
‚îî‚îÄ‚îÄ ...
```

## Configura√ß√£o do Backend

### 1. Instalar Depend√™ncias

```bash
cd backend
pip install -r requirements.txt
```

### 2. Configurar Token da API Hugging Face

**IMPORTANTE**: Este √© o passo mais importante para usar o modelo MedGemma!

Crie um arquivo `.env` na pasta `backend/` com:

```env
HUGGINGFACE_API_TOKEN=seu-token-real-aqui
```

**Como obter o token:**

1. Acesse [Hugging Face](https://huggingface.co/)
2. Fa√ßa login ou crie uma conta
3. V√° em Settings ‚Üí Access Tokens
4. Crie um novo token com permiss√µes de leitura
5. Copie o token e cole no arquivo `.env`

**Exemplo de arquivo `.env`:**

```env
HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
MEDGEMMA_MODEL_URL=https://api-inference.huggingface.co/models/google/medgemma-2b
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000
MAX_NEW_TOKENS=1000
TEMPERATURE=0.7
TOP_P=0.9
```

**Configura√ß√µes opcionais:**

- `MEDGEMMA_MODEL_URL`: URL do modelo (padr√£o: MedGemma 2B)
- `MAX_NEW_TOKENS`: M√°ximo de tokens gerados (padr√£o: 1000)
- `TEMPERATURE`: Criatividade do modelo (padr√£o: 0.7)
- `TOP_P`: Controle de diversidade (padr√£o: 0.9)

### 3. Executar o Backend

```bash
cd backend
python main.py
```

O backend estar√° dispon√≠vel em: `http://localhost:8000`

## Configura√ß√£o do Frontend

### 1. Instalar Depend√™ncias

```bash
npm install
```

### 2. Configurar URL do Backend

Crie um arquivo `.env.local` na raiz do projeto:

```env
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000
```

### 3. Executar o Frontend

```bash
npm run dev
```

O frontend estar√° dispon√≠vel em: `http://localhost:3000`

## Verifica√ß√£o da Conex√£o

### 1. Status do Backend

O componente `BackendStatus` na interface mostra:

- üü¢ **ONLINE**: Backend conectado e funcionando
- üî¥ **OFFLINE**: Backend n√£o est√° acess√≠vel
- üü° **VERIFICANDO**: Testando conectividade

### 2. Teste Manual

Acesse: `http://localhost:8000/health`
Resposta esperada: `{"status": "healthy", "pil_available": true/false}`

### 3. Verificar Configura√ß√£o do Hugging Face

O backend agora verifica automaticamente se o token est√° configurado:

**Se o token estiver configurado corretamente:**

- O sistema tentar√° usar o modelo MedGemma
- Voc√™ ver√° a mensagem: "Relat√≥rio gerado com sucesso usando modelo MedGemma"

**Se o token n√£o estiver configurado:**

- Voc√™ ver√° a mensagem: "Token da API Hugging Face n√£o configurado"
- O sistema retornar√° um relat√≥rio demonstrativo

### 4. Diagn√≥stico Autom√°tico

Se o modelo n√£o estiver funcionando, execute o script de diagn√≥stico:

```bash
cd backend
python diagnose.py
```

Este script verificar√°:

- ‚úÖ Arquivo `.env` existe e est√° configurado
- ‚úÖ Vari√°veis de ambiente est√£o carregadas
- ‚úÖ Depend√™ncias Python est√£o instaladas
- ‚úÖ Configura√ß√£o pode ser importada

## Endpoints da API

### Backend Python (`localhost:8000`)

- `GET /` - P√°gina inicial
- `GET /health` - Status de sa√∫de
- `POST /generate_report` - Gerar relat√≥rio m√©dico

### Frontend Next.js (`localhost:3000`)

- `/` - Interface principal
- `/api/generate_report` - **DEPRECIADO** (agora chama diretamente o backend)

## Fluxo de Dados

1. **Upload de Imagem**: Usu√°rio faz upload de imagem m√©dica
2. **Dados do Paciente**: Preenchimento de idade, peso e hist√≥rico
3. **Requisi√ß√£o ao Backend**: Frontend envia dados para `localhost:8000/generate_report`
4. **Processamento IA**: Backend processa imagem com modelo MedGemma
5. **Resposta**: Relat√≥rio m√©dico retorna para o frontend
6. **Exibi√ß√£o**: Relat√≥rio √© mostrado na interface

## Solu√ß√£o de Problemas

### Backend n√£o conecta

- Verifique se o Python est√° rodando na porta 8000
- Confirme se as depend√™ncias est√£o instaladas
- Verifique logs de erro no terminal

### CORS Errors

- O backend j√° est√° configurado com CORS habilitado
- Se persistir, verifique se o frontend est√° na origem permitida

### Token do Hugging Face n√£o funciona

- Verifique se o arquivo `.env` est√° na pasta `backend/`
- Confirme se o token come√ßa com `hf_`
- Teste o token no site do Hugging Face
- Verifique se o token tem permiss√µes de leitura

### Imagem n√£o processa com IA

- Verifique se o token da API Hugging Face est√° configurado corretamente
- Confirme se a imagem est√° em formato suportado (JPG, PNG)
- Verifique o tamanho da imagem (m√°ximo 10MB)
- Verifique os logs do backend para erros espec√≠ficos da API

### Erro "Invalid response format from Hugging Face API"

- A API do Hugging Face pode retornar diferentes formatos
- O sistema foi atualizado para lidar com m√∫ltiplos formatos
- Se persistir, verifique se o modelo MedGemma est√° dispon√≠vel

## Configura√ß√£o de Produ√ß√£o

### Backend

```python
# Em main.py, altere:
allow_origins=["https://seu-dominio.com"]  # Ao inv√©s de ["*"]
```

### Frontend

```env
NEXT_PUBLIC_BACKEND_URL=https://seu-backend.com
```

## Arquivos de Configura√ß√£o

- `lib/config.ts` - Configura√ß√µes da API
- `env.example` - Exemplo de vari√°veis de ambiente
- `backend/main.py` - Configura√ß√µes do servidor FastAPI

## Depend√™ncias Principais

### Backend

- FastAPI
- Uvicorn
- Pillow (PIL)
- Requests
- Transformers (Hugging Face)

### Frontend

- Next.js 14
- React
- TypeScript
- Tailwind CSS
- Shadcn/ui
