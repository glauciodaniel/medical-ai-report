#!/usr/bin/env python3
"""
Script para testar o endpoint personalizado do Hugging Face
"""

import os
import requests
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def test_custom_endpoint():
    """Testa o endpoint personalizado do Hugging Face"""
    
    # Get configuration
    token = os.getenv("HUGGINGFACE_API_TOKEN")
    model_url = os.getenv("MEDGEMMA_MODEL_URL", "https://u9yyy2quq9hdyqbu.us-east-1.aws.endpoints.huggingface.cloud")
    
    print("ğŸ§ª TESTANDO ENDPOINT PERSONALIZADO DO HUGGING FACE")
    print("=" * 60)
    
    if not token:
        print("âŒ HUGGINGFACE_API_TOKEN nÃ£o configurado!")
        return False
    
    print(f"ğŸ”‘ Token: {token[:20]}...")
    print(f"ğŸŒ Endpoint: {model_url}")
    
    # Test 1: Simple text generation
    print("\nğŸ“ Teste 1: GeraÃ§Ã£o de texto simples")
    headers = {"Authorization": f"Bearer {token}"}
    
    payload = {
        "inputs": "Hello, this is a test message for medical AI analysis.",
        "parameters": {
            "max_new_tokens": 50,
            "temperature": 0.7
        }
    }
    
    try:
        print("ğŸ”„ Enviando requisiÃ§Ã£o...")
        response = requests.post(model_url, headers=headers, json=payload, timeout=30)
        
        print(f"ğŸ“Š Status: {response.status_code}")
        print(f"ğŸ“‹ Headers: {dict(response.headers)}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Resposta: {result}")
        else:
            print(f"âŒ Erro: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Erro na requisiÃ§Ã£o: {e}")
        return False
    
    # Test 2: Medical image analysis (simulated)
    print("\nğŸ–¼ï¸  Teste 2: AnÃ¡lise de imagem mÃ©dica (simulada)")
    
    # Create a simple test image (1x1 pixel PNG)
    test_image = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=="
    
    medical_prompt = f"""
    Analyze the following medical image and provide a comprehensive medical report.
    
    Patient Information:
    - Age: 70 years
    - Weight: 70 kg
    - Clinical History: Cardiac
    
    Please provide:
    1. Image quality assessment
    2. Anatomical structures visible
    3. Pathological findings (if any)
    4. Clinical impression
    5. Recommendations for further evaluation
    
    Format the response as a professional medical report in Portuguese (Brazil).
    """
    
    payload = {
        "inputs": medical_prompt,
        "parameters": {
            "max_new_tokens": 200,
            "temperature": 0.7
        }
    }
    
    try:
        print("ğŸ”„ Enviando anÃ¡lise mÃ©dica...")
        response = requests.post(model_url, headers=headers, json=payload, timeout=60)
        
        print(f"ğŸ“Š Status: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… AnÃ¡lise mÃ©dica: {result}")
            
            # Check if it's a medical response
            if isinstance(result, list) and len(result) > 0:
                text = result[0].get('generated_text', '') or result[0].get('text', '')
                if 'medical' in text.lower() or 'relatÃ³rio' in text.lower() or 'anÃ¡lise' in text.lower():
                    print("ğŸ¯ Resposta parece ser mÃ©dica!")
                else:
                    print("âš ï¸  Resposta nÃ£o parece ser mÃ©dica")
            elif isinstance(result, dict):
                text = result.get('generated_text', '') or result.get('text', '')
                if 'medical' in text.lower() or 'relatÃ³rio' in text.lower() or 'anÃ¡lise' in text.lower():
                    print("ğŸ¯ Resposta parece ser mÃ©dica!")
                else:
                    print("âš ï¸  Resposta nÃ£o parece ser mÃ©dica")
        else:
            print(f"âŒ Erro na anÃ¡lise mÃ©dica: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Erro na anÃ¡lise mÃ©dica: {e}")
        return False
    
    print("\n" + "=" * 60)
    print("ğŸ‰ TESTE CONCLUÃDO!")
    print(f"âœ… Endpoint: {model_url}")
    print(f"âœ… Token: Configurado")
    print(f"âœ… RequisiÃ§Ãµes: Funcionando")
    
    return True

def test_endpoint_info():
    """Testa informaÃ§Ãµes do endpoint"""
    print("\nğŸ” INFORMAÃ‡Ã•ES DO ENDPOINT")
    print("=" * 40)
    
    model_url = os.getenv("MEDGEMMA_MODEL_URL", "https://u9yyy2quq9hdyqbu.us-east-1.aws.endpoints.huggingface.cloud")
    
    # Parse URL
    if "us-east-1.aws.endpoints.huggingface.cloud" in model_url:
        print("ğŸŒ Tipo: Endpoint personalizado AWS")
        print("ğŸ“ RegiÃ£o: us-east-1 (Norte da VirgÃ­nia)")
        print("ğŸ¢ Provedor: AWS")
    elif "api-inference.huggingface.co" in model_url:
        print("ğŸŒ Tipo: API oficial Hugging Face")
        print("ğŸ“ RegiÃ£o: Global")
        print("ğŸ¢ Provedor: Hugging Face")
    else:
        print("ğŸŒ Tipo: Endpoint customizado")
        print("ğŸ“ URL: Personalizada")
        print("ğŸ¢ Provedor: Desconhecido")
    
    print(f"ğŸ”— URL: {model_url}")

if __name__ == "__main__":
    print("ğŸ¥ TESTE DO ENDPOINT PERSONALIZADO - Medical AI Report")
    print("=" * 70)
    
    # Test endpoint info
    test_endpoint_info()
    
    # Test functionality
    success = test_custom_endpoint()
    
    print("\n" + "=" * 70)
    if success:
        print("ğŸ‰ ENDPOINT FUNCIONANDO! O modelo MedGemma deve estar operacional")
        print("\nğŸš€ Para usar no backend:")
        print("   1. Reinicie o backend: python main.py")
        print("   2. Teste com uma imagem real")
    else:
        print("âš ï¸  PROBLEMAS IDENTIFICADOS NO ENDPOINT")
        print("\nğŸ”§ Verifique:")
        print("   - Se o token estÃ¡ correto")
        print("   - Se o endpoint estÃ¡ ativo")
        print("   - Se o modelo estÃ¡ carregado")
        print("   - Logs de erro para mais detalhes")
